model: "azure:gpt-4o"
envFile:
  - "/home/paul/.env.genaiscript"
  - "/home/paul/.dotfiles/.env.genaiscript.config"
include:
  - "/home/paul/.dotfiles/genaiscript-samples/**/*.genai.mts"
  - "/home/paul/.dotfiles/genaiscript/**/*.genai.mts"
modelAliases:
  qwq: "ollama:qwq:latest"
  code: "ollama:qwen2.5-coder:32b-instruct-q5_K_M"
  llama31: "ollama:llama3.1:8b-instruct-q8_0"
  llama31hot:
    model: "ollama:llama3.1:8b-instruct-q8_0"
    temperature: 2
  qwen: "ollama:qwen2.5:32b-instruct-q5_K_S"
  # hf.co/ymcki/Llama-3_1-Nemotron-51B-Instruct-GGUF:IQ3_XXS
  # hf.co/ymcki/Llama-3_1-Nemotron-51B-Instruct-GGUF:IQ3_S
  llama32: "ollama:llama3.2:3b-instruct-q8_0"
  # MFDoom/deepseek-r1-tool-calling:32b-qwen-distill-q4_K_M
  # MFDoom/deepseek-r1-tool-calling:14b-qwen-distill-q4_K_M
  # qwq:32b-q4_K_M
  mistral-small: "ollama:mistral-small3.1:24b-instruct-2503-q4_K_M"
  deepseek: "ollama:deepseek-r1:32b-qwen-distill-q4_K_M"
  gemma: "gemma3:12b-it-q8_0"
  # mistral-small3.1:latest
  # qwen:14b-chat-q5_K_M
  # mistral:7b-instruct-q5_K_M
  # tinyllama:latest
